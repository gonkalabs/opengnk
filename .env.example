# Wallet credentials
# Create account: ./inferenced create-client <name> --node-address <NODE_URL>
# Export key:     ./inferenced keys export <name> --unarmored-hex --unsafe

# Option A: multiple wallets (recommended for higher throughput)
# Comma-separated list of private_key:address pairs.
# The address part is optional and will be derived from the key if omitted.
# Requests are routed across wallets in round-robin order.
#
# GONKA_WALLETS=privkey1:gonka1addr1,privkey2:gonka1addr2

# Option B: single wallet (backward compatible)
GONKA_PRIVATE_KEY=your_hex_private_key_here
GONKA_ADDRESS=gonka1your_address_here

# Source node for endpoint discovery (any genesis node works)
GONKA_SOURCE_URL=http://node1.gonka.ai:8000

# Features
# Rewrites tool/function-call requests into plain prompts and converts the
# model's JSON response back to proper tool_calls format.
SIMULATE_TOOL_CALLS=true

# Privacy sanitization
#
# Strips sensitive data from messages before forwarding to the upstream LLM
# and restores original values in the response. Three layers are available;
# enable as many as you need.
#
# Start with the sanitize profile:
#   docker compose --profile sanitize up -d

# Layer 1: enable sanitization at all (required for layers 2 and 3)
SANITIZE=true

# Layer 2: NER sidecar - catches person names, organisations, locations
# Requires the sanitize-ner container from the sanitize Docker profile.
SANITIZE_NER=true
SANITIZE_NER_URL=http://sanitize-ner:8001

# Layer 3: local LLM classifier - catches API keys, passwords, credentials,
# and anything else contextually sensitive that NER would miss.
# Requires the ollama container from the sanitize Docker profile.
# Pull the model on first run:
#   docker compose --profile sanitize run --rm ollama-init
SANITIZE_LLM=true
SANITIZE_LLM_URL=http://ollama:11434
SANITIZE_LLM_MODEL=qwen3:4b-instruct-2507-q4_K_M
SANITIZE_LLM_THRESHOLD=0

# Server
PORT=8080